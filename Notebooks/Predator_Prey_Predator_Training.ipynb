{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1N1HczZm-8T"
      },
      "outputs": [],
      "source": [
        "!pip install imageio > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA4N7PnvnhKQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "PATH_TO_ENVIRONMENT = '/content/drive/MyDrive/Master_Thesis/Final/Predator-Prey_Environment'\n",
        "PATH_TO_ALGORITHMS = '/content/drive/MyDrive/Master_Thesis/Final/Algorithm'\n",
        "PATH_TO_SAVE_MODEL = '/content/drive/MyDrive/Master_Thesis/Final/Algorithm/Predator.pth'\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp {PATH_TO_ALGORITHMS}/colab_helpers.py /content\n",
        "!cp {PATH_TO_ALGORITHMS}/A2C.py /content\n",
        "\n",
        "!cp -r {PATH_TO_ENVIRONMENT}/utils /content\n",
        "!cp -r {PATH_TO_ENVIRONMENT}/render_utils /content\n",
        "!cp -r {PATH_TO_ENVIRONMENT}/entities /content\n",
        "!cp -r {PATH_TO_ENVIRONMENT}/colliders /content\n",
        "!cp {PATH_TO_ENVIRONMENT}/environment.py /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ycjYog78ir7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from A2C import AgentA2C\n",
        "from colab_helpers import save_video, show_video\n",
        "from environment import Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIzgev4FFvHw"
      },
      "outputs": [],
      "source": [
        "# Path to save generated videos\n",
        "VIDEO_FILE_PATH = '.'\n",
        "\n",
        "# Mode in which environment is rendered\n",
        "RENDER_MODE = 'rgb_array'\n",
        "\n",
        "# Total number od episoded from which data to train VAE will be collected\n",
        "TOTAL_EPISODES = 2500\n",
        "\n",
        "# Time steps in single episode\n",
        "TIME_STEPS = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6BOtdBpFfLC"
      },
      "outputs": [],
      "source": [
        "env = Environment(render_mode=RENDER_MODE,\n",
        "                  plants_count=0,\n",
        "                  preys_initial_count=100,\n",
        "                  prey_reproduction=False,\n",
        "                  prey_hunger_decay=False,\n",
        "                  prey_thirst_decay=False,\n",
        "                  predators_initial_count=1,\n",
        "                  predator_reproduction=False,\n",
        "                  predator_render_collision_outline=True,\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dehk6028GjLb"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "\n",
        "action_space = 4\n",
        "observation_space = 17\n",
        "\n",
        "action_space_prey = 3\n",
        "\n",
        "for predator in env.get_predators():\n",
        "  print(env.obs_predator(predator))\n",
        "\n",
        "env.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32ZiJwlBHS8J"
      },
      "outputs": [],
      "source": [
        "frames = []\n",
        "state = env.reset()\n",
        "total_reward = 0\n",
        "\n",
        "for time_step in range(TIME_STEPS):\n",
        "  done = False\n",
        "\n",
        "  for prey in env.get_preys():\n",
        "    env.dummy_step_prey(prey, np.random.randint(0, action_space_prey))\n",
        "\n",
        "  for predator in env.get_predators():\n",
        "    env.step_predator(predator, np.random.randint(0, action_space))\n",
        "\n",
        "    if not predator.is_alive():\n",
        "      done = True\n",
        "\n",
        "  env.step()\n",
        "\n",
        "  frame = env.render()\n",
        "  frames.append(frame)\n",
        "\n",
        "  if done:\n",
        "    break\n",
        "\n",
        "save_video(frames, f'{VIDEO_FILE_PATH}/Test of environment')\n",
        "show_video(f'{VIDEO_FILE_PATH}/Test of environment.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVUFUQh6lYPh"
      },
      "outputs": [],
      "source": [
        "all_rewards = []\n",
        "\n",
        "for episode in range(TOTAL_EPISODES):\n",
        "  env.reset()\n",
        "  for prey in env.get_preys():\n",
        "    prey._hunger_decay = 0\n",
        "    prey._thirst_decay = 0\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  for time_step in range(TIME_STEPS):\n",
        "    done = False\n",
        "    for prey in env.get_preys():\n",
        "      env.dummy_step_prey(prey, np.random.randint(0, action_space_prey))\n",
        "\n",
        "    for predator in env.get_predators():\n",
        "      _, reward, done = env.step_predator(predator, np.random.randint(0, action_space))\n",
        "\n",
        "      if not predator.is_alive():\n",
        "        done = True\n",
        "\n",
        "    env.step()\n",
        "    total_reward += reward\n",
        "\n",
        "    if done or time_step == TIME_STEPS - 1:\n",
        "      print(f\"\\rEpisode: {episode}, Reward: {total_reward}, Time steps: {time_step}\", end=\"\")\n",
        "      break\n",
        "\n",
        "  all_rewards.append(total_reward)\n",
        "\n",
        "average_reward = sum(all_rewards) / TOTAL_EPISODES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDYC1bfxIRCP"
      },
      "outputs": [],
      "source": [
        "window_size = 100\n",
        "moving_average = np.convolve(all_rewards, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(all_rewards, label='Nagroda na epizod')\n",
        "plt.plot(range(window_size-1, len(all_rewards)), moving_average, color='orange', linestyle='-', label=f'Średnia krocząca (rozmiar okna={window_size})')\n",
        "plt.axhline(average_reward, color='r', linestyle='--', label=f'Średnia nagroda: {average_reward:.2f}')\n",
        "plt.xlabel('Epizod', fontsize=16)\n",
        "plt.ylabel('Całkowita nagroda', fontsize=16)\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd2aswt8Q7a6"
      },
      "outputs": [],
      "source": [
        "agent = AgentA2C(action_space, observation_space, units=256, dropout=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ChxNkVoQ9MX"
      },
      "outputs": [],
      "source": [
        "all_rewards = []\n",
        "\n",
        "for episode in range(TOTAL_EPISODES):\n",
        "  env.reset()\n",
        "\n",
        "  for predator in env.get_predators():\n",
        "    obs = env.obs_predator(predator)\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  for time_step in range(TIME_STEPS):\n",
        "\n",
        "    for prey in env.get_preys():\n",
        "      env.dummy_step_prey(prey, np.random.randint(0, action_space_prey))\n",
        "\n",
        "    for predator in env.get_predators():\n",
        "      action = agent.act(obs)\n",
        "      next_obs, reward, done = env.step_predator(predator, action)\n",
        "      agent.remember(obs, action, reward, done)\n",
        "      obs = next_obs\n",
        "\n",
        "    env.step()\n",
        "    total_reward += reward\n",
        "\n",
        "    if done or time_step == TIME_STEPS - 1:\n",
        "      print(f\"\\rEpisode: {episode}, Reward: {total_reward}, Time steps: {time_step}\", end=\"\")\n",
        "      agent.get_last_state(next_obs)\n",
        "      agent.learn()\n",
        "      break\n",
        "\n",
        "  all_rewards.append(total_reward)\n",
        "\n",
        "agent.save(PATH_TO_SAVE_MODEL)\n",
        "average_reward = sum(all_rewards) / TOTAL_EPISODES\n",
        "print()\n",
        "print(\"Average reward:\", average_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u9HcmHHYoou"
      },
      "outputs": [],
      "source": [
        "window_size = 100\n",
        "moving_average = np.convolve(all_rewards, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(all_rewards, label='Nagroda na epizod')\n",
        "plt.plot(range(window_size-1, len(all_rewards)), moving_average, color='orange', linestyle='-', label=f'Średnia krocząca (rozmiar okna={window_size})')\n",
        "plt.axhline(average_reward, color='r', linestyle='--', label=f'Średnia nagroda: {average_reward:.2f}')\n",
        "plt.xlabel('Epizod', fontsize=16)\n",
        "plt.ylabel('Całkowita nagroda', fontsize=16)\n",
        "plt.legend(loc='lower center')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVa_QpQohPUQ"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "axes[0].plot(agent.actor.loss_history, label='Strata aktora na epizod', color='blue')\n",
        "axes[0].set_xlabel('Epizod', fontsize=16)\n",
        "axes[0].set_ylabel('Strata', fontsize=16)\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(agent.critic.loss_history, label='Strata krytyka na epizod', color='red')\n",
        "axes[1].set_xlabel('Epizod', fontsize=16)\n",
        "axes[1].set_ylabel('Strata', fontsize=16)\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}